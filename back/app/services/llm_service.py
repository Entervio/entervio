"""LLM Service using Google Gemini for Interview Scenarios"""
import google.generativeai as genai
from typing import List, Dict, Literal
import logging
from app.core.config import settings
import json

# Setup logging
logger = logging.getLogger(__name__)

InterviewerType = Literal["nice", "neutral", "mean"]

# Base interview instructions (common to all types)
BASE_INTERVIEW_INSTRUCTIONS = """Tu es un recruteur professionnel franÃ§ais qui mÃ¨ne un entretien d'embauche.

RÃˆGLES CRITIQUES - FEEDBACK CONCIS:
- Donne des feedbacks TRÃˆS COURTS (1-2 phrases maximum)
- NE PAS Ã©crire de longs paragraphes de fÃ©licitations
- NE PAS dire "c'est excellent", "vous Ãªtes gÃ©nial", "parfait" Ã  rÃ©pÃ©tition
- Feedback format: "Bien." ou "IntÃ©ressant." puis PASSE Ã€ LA QUESTION SUIVANTE
- Exemple: "D'accord, je comprends. Parlons maintenant de..."

STRUCTURE DE L'ENTRETIEN:
- L'entretien doit durer environ 5 questions au total
- Compte mentalement les questions posÃ©es
- AprÃ¨s la 5Ã¨me question, conclus naturellement l'entretien
- Questions: 1) PrÃ©sentation, 2) ExpÃ©rience clÃ©, 3) CompÃ©tences techniques, 4) Motivations, 5) Question de situation/dÃ©fi

STYLE DE QUESTIONS:
- Questions directes et professionnelles
- Pas de questions trop longues
- Ã‰coute les rÃ©ponses et adapte-toi
- Pose des questions de suivi si nÃ©cessaire mais reste dans la limite de 5 questions totales"""

# Interviewer personality prompts
INTERVIEWER_PROMPTS = {
    "nice": """PERSONNALITÃ‰: Recruteur Bienveillant et Encourageant

Tu es chaleureux, positif et encourageant. Tu mets le candidat Ã  l'aise.

COMPORTEMENT:
- Ton accueillant et amical
- Souris dans ta voix (utilise un langage positif)
- Encourage le candidat: "C'est trÃ¨s bien", "J'aime votre approche"
- Feedbacks positifs mais COURTS: "Super." puis question suivante
- CrÃ©e une atmosphÃ¨re dÃ©tendue et confortable
- Reformule positivement: "IntÃ©ressant, et si on parlait de..."

EXEMPLE DE STYLE:
âŒ MAUVAIS: "Wow, c'est absolument fantastique ! Votre expÃ©rience est vraiment impressionnante et montre une grande maturitÃ© professionnelle. Je suis vraiment ravi d'entendre cela !"
âœ… BON: "TrÃ¨s bien, j'apprÃ©cie votre franchise. Maintenant, parlez-moi d'un projet technique..."

IMPORTANT: Reste bienveillant mais CONCIS dans tes feedbacks.""",

    "neutral": """PERSONNALITÃ‰: Recruteur Professionnel et Objectif

Tu es neutre, factuel et professionnel. Tu Ã©values objectivement sans Ãªtre ni trop chaleureux ni froid.

COMPORTEMENT:
- Ton professionnel et mesurÃ©
- Feedbacks factuels et COURTS: "D'accord." puis question suivante
- Pas d'Ã©motions excessives (ni trop positif ni nÃ©gatif)
- Questions directes et claires
- Ã‰coute attentive mais sans commentaires Ã©laborÃ©s
- Transitions neutres: "Je vois. Passons Ã ...", "Compris. Maintenant..."

EXEMPLE DE STYLE:
âŒ MAUVAIS: "Merci pour cette rÃ©ponse dÃ©taillÃ©e. C'est effectivement une approche intÃ©ressante qui dÃ©montre votre capacitÃ© d'analyse."
âœ… BON: "D'accord. Parlez-moi d'une situation difficile que vous avez gÃ©rÃ©e."

IMPORTANT: Reste neutre et CONCIS dans tes feedbacks.""",

    "mean": """PERSONNALITÃ‰: Recruteur Exigeant et Direct

Tu es exigeant, critique et direct. Tu testes la rÃ©sistance au stress du candidat.

COMPORTEMENT:
- Ton sec et direct, parfois lÃ©gÃ¨rement sarcastique
- Feedbacks critiques mais COURTS: "Hmm." ou "On verra." puis question suivante
- Questions qui challengent le candidat
- RelÃ¨ve les faiblesses: "C'est tout ?", "PlutÃ´t banal."
- CrÃ©e une lÃ©gÃ¨re pression (reste professionnel, pas insultant)
- Scepticisme dans les transitions: "Bien, et concrÃ¨tement...", "Passons Ã  autre chose."

EXEMPLE DE STYLE:
âŒ MAUVAIS: "Votre rÃ©ponse manque vraiment de substance et je dois dire que je m'attendais Ã  beaucoup mieux de la part d'un candidat avec votre profil."
âœ… BON: "Hmm, c'est vague. Donnez-moi un exemple concret avec des rÃ©sultats chiffrÃ©s."

IMPORTANT: Sois exigeant mais garde des feedbacks COURTS. Ne sois pas mÃ©chant, juste direct et exigeant."""
}

def get_system_prompt(interviewer_type: InterviewerType) -> str:
    """Get the complete system prompt for the given interviewer type."""
    return f"{BASE_INTERVIEW_INSTRUCTIONS}\n\n{INTERVIEWER_PROMPTS[interviewer_type]}"


class LLMService:
    def __init__(self):
        """Initialize with Google Gemini using settings from config."""
        logger.info("ðŸ”„ Initializing LLMService...")
        
        # Get API key from settings
        api_key = settings.GEMINI_API_KEY
        
        if not api_key:
            error_msg = (
                "âŒ GEMINI_API_KEY not found! "
                "Please add it to your .env file: GEMINI_API_KEY=..."
            )
            logger.error(error_msg)
            raise ValueError(error_msg)
        
        logger.info(f"âœ“ Found GEMINI_API_KEY: {api_key[:10]}...{api_key[-5:]}")
        
        try:
            genai.configure(api_key=api_key)
            # Note: Model will be created per-session with appropriate system prompt
            logger.info("âœ… Gemini client initialized successfully!")
        except Exception as e:
            logger.error(f"âŒ Failed to initialize Gemini client: {str(e)}")
            raise
    
    def _create_model(self, interviewer_type: InterviewerType):
        """Create a Gemini model with the appropriate system prompt."""
        system_prompt = get_system_prompt(interviewer_type)
        return genai.GenerativeModel(
            'gemini-2.5-flash-lite',
            system_instruction=system_prompt
        )

    def _create_grading_model(self, interviewer_type: InterviewerType):
        """Create a gemini model to grade the user responses"""
        system_prompt = get_system_prompt(interviewer_type)
        return genai.GenerativeModel(
            'gemini-2.5-flash-lite',
            system_instruction=system_prompt,
            generation_config={
                "response_mime_type": "application/json"
            }
        )
    
    def get_initial_greeting(
        self, 
        candidate_name: str, 
        interviewer_type: InterviewerType
    ) -> str:
        """
        Generate personalized initial greeting based on interviewer type.
        
        Args:
            candidate_name: The candidate's name
            interviewer_type: Type of interviewer (nice, neutral, mean)
            
        Returns:
            Personalized greeting message
        """
        logger.info(f"ðŸ‘‹ Generating greeting for {candidate_name} with {interviewer_type} interviewer")
        
        greetings = {
            "nice": f"""Bonjour {candidate_name} ! Je suis absolument ravi de vous rencontrer aujourd'hui. 

Je serai votre interlocuteur pour cet entretien et je veux que vous vous sentiez parfaitement Ã  l'aise. Mon objectif est de dÃ©couvrir qui vous Ãªtes vraiment, vos talents et vos aspirations.

N'hÃ©sitez surtout pas Ã  Ãªtre vous-mÃªme - il n'y a pas de mauvaises rÃ©ponses ici ! Je suis simplement curieux d'en apprendre plus sur vous.

Pour commencer, pourriez-vous vous prÃ©senter en quelques mots ? Parlez-moi de votre parcours.""",

            "neutral": f"""Bonjour {candidate_name}. 

Je serai votre interlocuteur aujourd'hui. L'objectif de cet entretien est d'Ã©valuer votre profil, vos compÃ©tences et votre adÃ©quation avec le poste.

Nous allons passer en revue votre expÃ©rience et vos motivations. Soyez prÃ©cis dans vos rÃ©ponses.

CommenÃ§ons. PrÃ©sentez-vous briÃ¨vement.""",

            "mean": f"""Bonjour {candidate_name}.

Je n'ai pas beaucoup de temps, alors allons droit au but. J'ai vu beaucoup de candidats cette semaine et franchement, peu m'ont impressionnÃ©.

J'attends des rÃ©ponses concrÃ¨tes, avec des exemples prÃ©cis et des rÃ©sultats mesurables. Pas de langue de bois.

PrÃ©sentez-vous. Et soyez synthÃ©tique."""
        }
        
        return greetings[interviewer_type]
    
    async def chat(
        self, 
        message: str, 
        conversation_history: List[Dict[str, str]],
        interviewer_type: InterviewerType
    ) -> str:
        """
        Send message to Gemini and get interviewer response.
        
        Args:
            message: Candidate's message
            conversation_history: List of previous messages
            interviewer_type: Type of interviewer
            
        Returns:
            Interviewer's response text
        """
        logger.info(f"ðŸ’¬ Processing candidate response with {interviewer_type} interviewer")
        
        try:
            # Create model with appropriate personality
            model = self._create_model(interviewer_type)
            
            # Convert conversation history to Gemini format
            history = []
            if conversation_history:
                for msg in conversation_history:
                    role = "model" if msg["role"] == "assistant" else msg["role"]
                    history.append({
                        "role": role,
                        "parts": [msg["content"]]
                    })
            
            # Start chat with history
            chat = model.start_chat(history=history)
            
            # Send message and get response
            response = chat.send_message(message)
            response_text = response.text
            
            logger.info(f"âœ… Got {interviewer_type} interviewer response ({len(response_text)} chars)")
            return response_text
            
        except Exception as e:
            logger.error(f"âŒ Chat error: {str(e)}")
            raise
    
    async def grade_response(
    self,
    question: str,
    answer: str,
    interviewer_type: InterviewerType
    ) -> Dict[str, any]:
        """
        Grade a candidate's response to an interview question.
        
        Args:
            question: The interview question asked
            answer: The candidate's answer
            interviewer_type: Type of interviewer (affects grading strictness)
            
        Returns:
            Dict with 'grade' (1-10) and 'feedback' (str)
        """
        logger.info(f"ðŸ“Š Grading response with {interviewer_type} interviewer...")
        
        try:
            # Create grading model with JSON output
            model = self._create_grading_model(interviewer_type)
            
            # Grading prompt with strict JSON schema
            grading_prompt = f"""Tu dois Ã©valuer la rÃ©ponse d'un candidat Ã  une question d'entretien.

                                QUESTION POSÃ‰E:
                                {question}

                                RÃ‰PONSE DU CANDIDAT:
                                {answer}

                                CONSIGNES D'Ã‰VALUATION:
                                - Note de 1 Ã  10 (1 = trÃ¨s mauvais, 10 = excellent)
                                - Feedback concis en franÃ§ais (2-3 phrases maximum)
                                - Ã‰value: pertinence, clartÃ©, exemples concrets, structure

                                RÃ©ponds UNIQUEMENT avec ce format JSON exact:
                                {{
                                "grade": 8,
                                "feedback": "RÃ©ponse claire avec un bon exemple. Manque de chiffres prÃ©cis."
                                }}"""

            # Generate response
            response = model.generate_content(grading_prompt)
            
            # Parse JSON response
            result = json.loads(response.text)
            
            logger.info(f"âœ… Response graded: {result['grade']}/10")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ Failed to parse JSON response: {str(e)}")
            logger.error(f"Raw response: {response.text}")
            # Fallback response
            return {
                "grade": 5,
                "feedback": "Erreur lors de l'Ã©valuation de la rÃ©ponse."
            }
        except Exception as e:
            logger.error(f"âŒ Grading error: {str(e)}")
            raise

    async def end_interview(
        self, 
        conversation_history: List[Dict[str, str]],
        interviewer_type: InterviewerType
    ) -> str:
        """
        Generate a summary and closing message for the interview.
        
        Args:
            conversation_history: Full conversation history
            interviewer_type: Type of interviewer
            
        Returns:
            Closing message with brief summary
        """
        logger.info(f"ðŸ“ Generating interview summary with {interviewer_type} interviewer...")
        
        try:
            # Create model with appropriate personality
            model = self._create_model(interviewer_type)
            
            # Convert conversation history
            history = []
            for msg in conversation_history:
                role = "model" if msg["role"] == "assistant" else msg["role"]
                history.append({
                    "role": role,
                    "parts": [msg["content"]]
                })
            
            chat = model.start_chat(history=history)
            
            # Personality-specific closing prompts
            closing_prompts = {
                "nice": """L'entretien touche Ã  sa fin. Fais un bref rÃ©sumÃ© trÃ¨s positif (2-3 phrases), 
                remercie chaleureusement le candidat et souhaite-lui bonne chance pour la suite.""",
                
                "neutral": """L'entretien est terminÃ©. Fais un rÃ©sumÃ© factuel en 2-3 phrases, 
                remercie le candidat professionnellement et indique que l'Ã©quipe reviendra vers lui.""",
                
                "mean": """L'entretien est fini. Fais un rÃ©sumÃ© critique mais constructif en 2-3 phrases, 
                mentionne ce qui pourrait Ãªtre amÃ©liorÃ©, remercie briÃ¨vement."""
            }
            
            response = chat.send_message(closing_prompts[interviewer_type])
            summary = response.text
            
            logger.info("âœ… Interview summary generated")
            return summary
            
        except Exception as e:
            logger.error(f"âŒ Error generating summary: {str(e)}")
            # Fallback messages by type
            fallbacks = {
                "nice": """Merci infiniment pour cet Ã©change ! J'ai vraiment apprÃ©ciÃ© votre sincÃ©ritÃ© 
                et votre enthousiasme. L'Ã©quipe reviendra trÃ¨s vite vers vous. Excellente journÃ©e !""",
                
                "neutral": """Merci pour cet entretien. L'Ã©quipe reviendra vers vous prochainement. 
                Bonne journÃ©e.""",
                
                "mean": """Bien. On a fait le tour. L'Ã©quipe vous contactera si votre profil nous intÃ©resse. 
                Au revoir."""
            }
            return fallbacks[interviewer_type]


# Singleton instance - initialized on first import
_llm_service_instance = None

def get_llm_service() -> LLMService:
    """Get or create the LLM service singleton."""
    global _llm_service_instance
    if _llm_service_instance is None:
        logger.info("ðŸš€ Creating llm_service singleton...")
        _llm_service_instance = LLMService()
        logger.info("âœ… llm_service singleton created!")
    return _llm_service_instance

# For convenience
llm_service = get_llm_service()